{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING QA BOT WITH PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training data\n",
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test data\n",
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data contains 10, 000 tuples. Each tuple holds a list comprehension of the story, question, and  a \"yes\"/\"no\" answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Story\n",
    "\" \".join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "\" \".join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_creator(data):\n",
    "    '''\n",
    "    Creating vocabulary of words present in our data\n",
    "    '''\n",
    "    vocab = set()\n",
    "    for story, question, answer in data:\n",
    "        vocab = vocab.union(set(story))\n",
    "        vocab = vocab.union(set(question))\n",
    "    vocab.add('yes')\n",
    "    vocab.add('no')\n",
    "    \n",
    "    tokenizer = Tokenizer(filters = [])\n",
    "    tokenizer.fit_on_texts(vocab)\n",
    "    \n",
    "    max_story_len = max([len(datum[0]) for datum in data]) #maximum story length\n",
    "    max_question_len = max([len(datum[1]) for datum in data]) #maximum question length\n",
    "    \n",
    "    return tokenizer, max_story_len, max_question_len, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, \n",
    "                      max_story_len = max_story_len, \n",
    "                      max_question_len = max_question_len):\n",
    "    '''\n",
    "    Vectorizes story, question, and answer with padded sequences\n",
    "    X = Stories\n",
    "    X_Q = Questions\n",
    "    Y  = Answers\n",
    "    '''\n",
    "    X  = []\n",
    "    X_Q = []\n",
    "    Y = []\n",
    "    \n",
    "    for stories ,questions, answers in data:\n",
    "        '''\n",
    "        For each story\n",
    "        [23,14,43,...]\n",
    "        '''\n",
    "        x = [word_index[word.lower()] for word in stories]\n",
    "        x_q = [word_index[word.lower()] for word in questions]\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        y[word_index[answers]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        X_Q.append(x_q)\n",
    "        Y.append(y)\n",
    "    return (pad_sequences(X, maxlen = max_story_len), pad_sequences(X_Q, maxlen = max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(train_data, test_data):\n",
    "    all_data = train_data + test_data # Combine train data and test data\n",
    "    \n",
    "    tokenizer, max_story_len, max_question_len, vocab = vocab_creator(all_data)    \n",
    "    vocab_size = len(vocab) + 1 #size of our vocabulary\n",
    "    \n",
    "    input_sequence = Input((max_story_len,)) #placeholder for shape = (max_story_len, batch_size)\n",
    "    question = Input((max_question_len,))\n",
    "    \n",
    "    return vocab_size, input_sequence, question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(vocab_size = vocab_size, max_question_len = max_question_len, input_sequence = input_sequence, question = question):\n",
    "    '''\n",
    "    Input Encoder M\n",
    "    Gets embedded to a seq of vecotrs\n",
    "    '''\n",
    "    input_encoder_m = Sequential()\n",
    "    input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim = 64))\n",
    "    input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "    '''\n",
    "    Input Encoder C\n",
    "    Gets embedded to a seq of vecotrs\n",
    "    '''\n",
    "    input_encoder_c = Sequential()\n",
    "    input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim = max_question_len))\n",
    "    input_encoder_c.add(Dropout(.3))\n",
    "    \n",
    "    '''\n",
    "    Question Encoder\n",
    "    '''\n",
    "    question_encoder = Sequential()\n",
    "    question_encoder.add(Embedding(input_dim=vocab_size, output_dim = 64, input_length = max_question_len))\n",
    "    question_encoder.add(Dropout(.3))\n",
    "    \n",
    "    '''\n",
    "    ENCODED RESULT <-- ENCODER(INPUT)\n",
    "    '''\n",
    "    input_encoded_m = input_encoder_m(input_sequence)\n",
    "    input_encoded_c = input_encoder_c(input_sequence)\n",
    "    question_encoded =  question_encoder(question)\n",
    "\n",
    "    '''\n",
    "    Use dot product to compute the match between the first input vector\n",
    "    seq and the query\n",
    "    '''\n",
    "    match = dot([input_encoded_m, question_encoded], axes =(2,2))\n",
    "    match = Activation('softmax')(match)\n",
    "    \n",
    "    '''\n",
    "    Add above match matrix to second input vector seq\n",
    "    '''\n",
    "    response = add([match, input_encoded_c])\n",
    "    response = Permute((2,1))(response) # convert it to have a output of samples dim by query_max_len by story_max_len\n",
    "    \n",
    "    '''\n",
    "    Now we can concat the match matrix with the question vector seq\n",
    "    '''\n",
    "    answer = concatenate([response, question_encoded])\n",
    "    answer = LSTM(32)(answer)\n",
    "    answer = Dropout(0.5)(answer)\n",
    "    answer = Dense(vocab_size)(answer) # (sample, vocab_size)\n",
    "    answer = Activation('softmax')(answer)\n",
    "    model = Model([input_sequence, question], answer)\n",
    "    model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, input_sequence, question = data_preprocessing(train_data, test_data)\n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.8615 - acc: 0.4930 - val_loss: 0.6939 - val_acc: 0.5030\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 3s 337us/step - loss: 0.7007 - acc: 0.5039 - val_loss: 0.6941 - val_acc: 0.5030\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 3s 340us/step - loss: 0.6957 - acc: 0.4978 - val_loss: 0.6935 - val_acc: 0.5030\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 3s 338us/step - loss: 0.6950 - acc: 0.4997 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 3s 339us/step - loss: 0.6950 - acc: 0.4946 - val_loss: 0.6943 - val_acc: 0.5030\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.6942 - acc: 0.5011 - val_loss: 0.6963 - val_acc: 0.4970\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.6949 - acc: 0.4955 - val_loss: 0.6937 - val_acc: 0.5030\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.6940 - acc: 0.5023 - val_loss: 0.6968 - val_acc: 0.5030\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.6943 - acc: 0.5073 - val_loss: 0.6935 - val_acc: 0.4770\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.6937 - acc: 0.5097 - val_loss: 0.6945 - val_acc: 0.4980\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.6940 - acc: 0.5036 - val_loss: 0.6938 - val_acc: 0.4820\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.6934 - acc: 0.5148 - val_loss: 0.6948 - val_acc: 0.4750\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.6914 - acc: 0.5241 - val_loss: 0.6983 - val_acc: 0.5050\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.6886 - acc: 0.5356 - val_loss: 0.6898 - val_acc: 0.5460\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.6737 - acc: 0.5737 - val_loss: 0.6725 - val_acc: 0.5740\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.6536 - acc: 0.6072 - val_loss: 0.6326 - val_acc: 0.6520\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.6345 - acc: 0.6418 - val_loss: 0.6191 - val_acc: 0.6680\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.6293 - acc: 0.6462 - val_loss: 0.6125 - val_acc: 0.6820\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.6122 - acc: 0.6746 - val_loss: 0.5869 - val_acc: 0.7080\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.5973 - acc: 0.6917 - val_loss: 0.5781 - val_acc: 0.7150\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.5777 - acc: 0.7081 - val_loss: 0.5415 - val_acc: 0.7380\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.5661 - acc: 0.7203 - val_loss: 0.5456 - val_acc: 0.7180\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.5511 - acc: 0.7298 - val_loss: 0.5244 - val_acc: 0.7490\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.5419 - acc: 0.7383 - val_loss: 0.5153 - val_acc: 0.7500\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.5334 - acc: 0.7455 - val_loss: 0.5070 - val_acc: 0.7620\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.5178 - acc: 0.7559 - val_loss: 0.5023 - val_acc: 0.7570\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.4942 - acc: 0.7649 - val_loss: 0.4630 - val_acc: 0.7820\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.4747 - acc: 0.7844 - val_loss: 0.4589 - val_acc: 0.7820\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.4467 - acc: 0.8019 - val_loss: 0.4379 - val_acc: 0.8050\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.4335 - acc: 0.8086 - val_loss: 0.4179 - val_acc: 0.8110\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.4131 - acc: 0.8216 - val_loss: 0.4086 - val_acc: 0.8090\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.3995 - acc: 0.8281 - val_loss: 0.4175 - val_acc: 0.8080\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.3896 - acc: 0.8343 - val_loss: 0.3857 - val_acc: 0.8240\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.3758 - acc: 0.8410 - val_loss: 0.3797 - val_acc: 0.8320\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.3774 - acc: 0.8415 - val_loss: 0.4081 - val_acc: 0.8190\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.3603 - acc: 0.8519 - val_loss: 0.4046 - val_acc: 0.8160\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.3536 - acc: 0.8514 - val_loss: 0.3849 - val_acc: 0.8250\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.3575 - acc: 0.8511 - val_loss: 0.3888 - val_acc: 0.8300\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.3504 - acc: 0.8540 - val_loss: 0.3936 - val_acc: 0.8270\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.3446 - acc: 0.8502 - val_loss: 0.3749 - val_acc: 0.8300\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.3369 - acc: 0.8592 - val_loss: 0.3745 - val_acc: 0.8240\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.3376 - acc: 0.8596 - val_loss: 0.3687 - val_acc: 0.8300\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.3285 - acc: 0.8623 - val_loss: 0.3837 - val_acc: 0.8220\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.3288 - acc: 0.8628 - val_loss: 0.3796 - val_acc: 0.8340\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.3278 - acc: 0.8624 - val_loss: 0.3863 - val_acc: 0.8360\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.3243 - acc: 0.8642 - val_loss: 0.3855 - val_acc: 0.8270\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.3241 - acc: 0.8596 - val_loss: 0.3857 - val_acc: 0.8310\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.3170 - acc: 0.8674 - val_loss: 0.3722 - val_acc: 0.8320\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.3184 - acc: 0.8644 - val_loss: 0.3696 - val_acc: 0.8280\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.3148 - acc: 0.8655 - val_loss: 0.3724 - val_acc: 0.8320\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size = 32, epochs = 50, validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
